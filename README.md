### âœ¨ Research Highlights âœ¨  [![GitHub User's stars](https://img.shields.io/github/stars/HongwenZhang?label=GitHub%20Stars&style=social)](https://github.com/HongwenZhang) [![Google Scholar Citations](https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhang-hongwen%2Fzhang-hongwen.github.io@gs-data%2Fgs_data_shieldsio.json&labelColor=ffffff&color=cef&style=flat&label=Google%20Scholar%20Citations)](https://scholar.google.com/citations?user=6z0m_ZMAAAAJ&hl=en)
<h1 align="center"> </h1>


### ðŸš© Human/Hand/Face/Full-body Motion Capture:

ðŸ‘‰ **DaNet [TPAMI 2020]**: [![GitHub stars](https://img.shields.io/github/stars/HongwenZhang/DaNet-DensePose2SMPL.svg?style=social&label=Star)](https://github.com/HongwenZhang/DaNet-DensePose2SMPL)
+ **[Learning 3D Human Shape and Pose from Dense Body Parts](https://hongwenzhang.github.io/DensePose2SMPL)**  
 âœ¨ DensePose to SMPL; part-based regressor; more robust to occlusion
<table style="margin-left:auto; margin-right:auto;">
  <tr>
    <td><a href="https://hongwenzhang.github.io/DensePose2SMPL"> <img src="https://hongwenzhang.github.io/DensePose2SMPL/img/framework.png" height=100px width=250px> </a></td>
    <td><a href="https://hongwenzhang.github.io/DensePose2SMPL"> <img src="https://user-images.githubusercontent.com/12066626/192428284-39c0bca3-04a2-4fe4-b272-48665b299dc8.png" height=100px width=300px> </a></td>
  </tr>
</table>
<!-- <h1 align="center"> </h1> -->

ðŸ‘‰ **PyMAF [ICCV 2021, Oral]** & **PyMAF-X [TPAMI 2023]**: [![GitHub stars](https://img.shields.io/github/stars/HongwenZhang/PyMAF.svg?style=social&label=Star)](https://github.com/HongwenZhang/PyMAF)
+ **[PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop](https://hongwenzhang.github.io/pymaf)**  
 âœ¨ better mesh-to-image alignment
<table style="margin-left:auto; margin-right:auto;">
  <tr>
    <td><a href="https://hongwenzhang.github.io/pymaf"> <img src="https://hongwenzhang.github.io/images/pymaf.jpg" height=100px width=220px> </a></td>
    <td><a href="https://hongwenzhang.github.io/pymaf"> <img src="https://hongwenzhang.github.io/pymaf/files/flashmob.gif" height=100px width=200px> </a></td>
  </tr>
</table>

+ **[PyMAF-X: Towards Well-aligned Full-body Model Regression from Monocular Images](https://www.liuyebin.com/pymaf-x)**  
 âœ¨ an eXpressive version of PyMAF, supporting SMPL-X
<table style="margin-left:auto; margin-right:auto;">
  <tr>
    <td><a href="https://www.liuyebin.com/pymaf-x"> <img src="https://hongwenzhang.github.io/pymaf-x/files/pymafx.png" height=100px width=220px> </a></td>
    <td><a href="https://www.liuyebin.com/pymaf-x"> <img src="https://liuyebin.com/thumbnail/pymaf-x.jpg" height=100px width=150px> </a></td>
    <td><a href="https://www.liuyebin.com/pymaf-x"> <img src="https://user-images.githubusercontent.com/12066626/213963277-41f26414-272f-4087-87a2-a9f9dcab2ea7.jpg" height=100px width=200px> </a></td>
  </tr>
</table>


<!-- <details>
<summary>click to view</summary>
<p> -->

ðŸ‘‰ **JVCR [TIP 2019]**: [![GitHub stars](https://img.shields.io/github/stars/HongwenZhang/JVCR-3Dlandmark.svg?style=social&label=Star)](https://github.com/HongwenZhang/JVCR-3Dlandmark)
 
+ **[Adversarial Learning Semantic Volume for 2D/3D Face Shape Regression in the Wild](https://github.com/HongwenZhang/JVCR-3Dlandmark)**  
 âœ¨ Joint voxel and coordinate regression
<table style="margin-left:auto; margin-right:auto;">
  <tr>
    <td><a href="https://github.com/HongwenZhang/JVCR-3Dlandmark"> <img src="https://user-images.githubusercontent.com/12066626/192295489-d5770b7d-d6ee-4ab8-a7c1-70552cb60d68.png" height=100px width=300px> </a></td>
    <td><a href="https://github.com/HongwenZhang/JVCR-3Dlandmark"> <img src="https://user-images.githubusercontent.com/12066626/192295603-23c56ba8-d011-4268-8e5e-6b6ae833a98d.png" height=100px width=300px> </a></td>
  </tr>
</table>

ðŸ‘‰ **ECT [TIFS 2018]**: [![GitHub stars](https://img.shields.io/github/stars/HongwenZhang/ECT-FaceAlignment.svg?style=social&label=Star)](https://github.com/HongwenZhang/ECT-FaceAlignment)

+ **[Combining Data-driven and Model-driven Methods for Robust Facial Landmark Detection](https://github.com/HongwenZhang/ECT-FaceAlignment)**  
 âœ¨ Robust to occlusions and expressions
<table style="margin-left:auto; margin-right:auto;">
  <tr>
    <td><a href="https://github.com/HongwenZhang/ECT-FaceAlignment"> <img src="https://user-images.githubusercontent.com/12066626/192287738-36284eb6-45de-4432-8026-65f854bb3321.png" height=100px width=200px> </a></td>
    <td><a href="https://github.com/HongwenZhang/ECT-FaceAlignment"> <img src="https://user-images.githubusercontent.com/12066626/192287461-2aa3181a-d638-48b0-84f6-3c913b6215b2.png" height=100px width=200px> </a></td>
  </tr>
</table>


ðŸ‘‰ [More projects](https://hongwenzhang.github.io) related to:

+ clothed human reconstruction
+ animatable avatar
+ behavior understanding
 
<!-- </p></details> -->
